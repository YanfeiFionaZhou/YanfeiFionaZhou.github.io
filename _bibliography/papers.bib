@inproceedings{zhou2024conformal,
  title={Conformal Classification with Equalized Coverage for Adaptively Selected Groups},
  author={Zhou, Yanfei and Sesia, Matteo},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024},
  selected={true},
  abbr={NeurIPS},
  url={https://neurips.cc/virtual/2024/poster/96713},
  poster={https://neurips.cc/media/PosterPDFs/NeurIPS%202024/96713.png?t=1731101453.4247527},
  code={https://github.com/FionaZ3696/Adaptively-Fair-Conformal-Prediction},
  abstract={This paper introduces a conformal inference method to evaluate uncertainty in classification by generating prediction sets with valid coverage conditional on adaptively chosen features. These features are carefully selected to reflect potential model limitations or biases. This can be useful to find a practical compromise between efficiency—by providing informative predictions—and algorithmic fairness—by ensuring equalized coverage for the most sensitive groups. We demonstrate the validity and effectiveness of this method on simulated and real data sets.},
  preview={AFCP.png},
  img={publication_preview/AFCP.png},
  img_caption={Prediction sets constructed with different methods for patients in groups negatively affected by algorithm bias. Our method (AFCP) is designed to provide informative prediction sets that are well-calibrated conditional on the automatically identified critical sensitive attribute.}
}

@inproceedings{zhou2024conformalized,
  title={Conformalized Adaptive Forecasting of Heterogeneous Trajectories},
  author={Zhou, Yanfei and Lindemann, Lars and Sesia, Matteo},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2024},
  selected={true},
  abbr={ICML},
  arxiv={2402.09623},
  url={https://icml.cc/virtual/2024/poster/33115},
  poster={https://icml.cc/media/PosterPDFs/ICML%202024/33115.png?t=1720764633.3923903},
  code={https://github.com/FionaZ3696/CAFHT},
  abstract={We present a new conformal method for generating simultaneous forecasting bands guaranteed to cover the entire path of a new random trajectory with sufficiently high probability. Prompted by the need for dependable uncertainty estimates in motion planning applications where the behavior of diverse objects may be more or less unpredictable, we blend different techniques from online conformal prediction of single and multiple time series and ideas for addressing heteroscedasticity in regression. This solution is both principled, providing precise finite-sample guarantees, and effective, often leading to more informative predictions than prior methods.},
  preview={cafht.png},
  img={publication_preview/cafht.png},
  img_caption={Conformal forecasting bands constructed using different methods, for the heterogeneous pedestrian trajectories. All methods guarantee covering entire path 90\% of test trajectories on average. Our method (CAFHT) can automatically adapt to the unpredictability of each trajectory.}
}

@inproceedings{liang2023conformal,
  title={Conformal inference is (almost) free for neural networks trained with early stopping},
  author={Liang, Ziyi and Zhou, Yanfei and Sesia, Matteo},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={20810--20851},
  year={2023},
  publisher={PMLR},
  selected={true},
  abbr={ICML},
  url={https://icml.cc/virtual/2023/poster/24975},
  poster={https://icml.cc/media/PosterPDFs/ICML%202023/24975.png?t=1687588201.2805715},
  code={https://github.com/ZiyiLiang/Conformalized_early_stopping},
  abstract={We propose conformalized early stopping, a method that combines early stopping with conformal calibration while efficiently reusing a single hold-out set. This yields models that are accurate and provide reliable uncertainty quantification without multiple data splits. We develop practical implementations for outlier detection, multiclass classification, and regression.},
  preview={CES.png},
  img={publication_preview/CES.png},
  img_caption={Conformal inference for models trained with early stopping. (a) Conventional pipeline requiring a three-way sample split. (b) Conformalized early stopping, requiring a two-way split. Our method (CES) is more data-efficient while maintaining reliability for conformal prediction.}
}

@inproceedings{einbinder2022training,
  title={Training uncertainty-aware classifiers with conformalized deep learning},
  author={Einbinder, Bat-Sheva and Romano, Yaniv and Sesia, Matteo and Zhou, Yanfei},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={22380--22395},
  year={2022},
  selected={true},
  abbr={NeurIPS},
  url={https://nips.cc/virtual/2022/poster/54954},
  poster={https://nips.cc/media/PosterPDFs/NeurIPS%202022/9407c826d8e3c07ad37cb2d13d1cb641.png?t=1667239153.6862524},
  code={https://github.com/bat-sheva/Conformal-Learning},
  abstract={We develop a training strategy for deep multiclass classification that improves model calibration, leading to more informative, reliable uncertainty estimates. Its core is a novel loss function that mitigates overfitting and overconfidence often observed with cross-entropy training. We show the method's reliability and efficiency on synthetic and real datasets such as CIFAR-10.},
  preview={ConformalTraining.png},
  img={publication_preview/ConformalTraining.png},
  img_caption={Two example test images from the preprocessed CIFAR-10 data set, with their top two estimated class probabilities computed by the output softmax layer of convolutional neural networks trained to minimize different loss functions. Left: intact image of a ship. Right: corrupted image of a dog. Models trained with our loss (Conformal) are less overconfident on the blurred image while maintaining confidence comparable to other losses on the intact image.}
}
